# AI Agent Prompt Library

This file contains a set of fully detailed, single-paragraph prompts designed for maximum effectiveness and deep context-awareness with AI coding agents. Each prompt is a self-contained, comprehensive methodology that mandates a deep, evidence-based analysis of the full-stack codebase to prevent hallucination and ensure high-quality output.

## **Universal Improvement Guidelines**

**TOKEN BUDGET MANAGEMENT:** Before each phase, estimate token usage. If approaching limits, create checkpoint summaries in the YAML file under `phaseCheckpoints:` key. Resume from checkpoints by reading only the summary and continuing where left off.

**ERROR RECOVERY:** If any tool fails, immediately log the error in `ai_task_analysis_notes_temp/[task].yaml` under `errors:` key with timestamp, tool name, and context. Attempt up to 3 retries with different approaches before escalating to user.

**CONTEXT REFRESH:** Every 5 file operations, re-read the current task's YAML summary section to maintain context. Before Phase 4 execution, create a consolidated `executionContext:` summary containing only essential information for implementation.

**SCOPE BOUNDARIES:** Limit `workQueue` processing to maximum 20 items per phase. Prioritize items by relevance score (direct dependencies = 3, inheritance = 2, usage = 1). If scope exceeds limit, document excluded items under `excludedFromScope:` and justify why.

**PROGRESS TRACKING:** Update `progress:` key in YAML with percentage complete and current operation. For Phase 1: track items processed/total. For Phase 4: track files created/modified/total planned.

**TOOL SELECTION STRATEGY:** Use semantic_search for finding similar patterns, grep_search for specific code snippets, file_search for exact filenames, read_file for detailed analysis. Always start with semantic_search to understand the domain before detailed analysis.

**BRAVOSUITE-SPECIFIC GUIDELINES:** For BravoSUITE codebase work, follow these critical patterns:

-   **Evidence-based approach:** Use `grep_search()` and `semantic_search()` to verify assumptions before implementation
-   **Service boundary discovery:** Find ports/endpoints via `grep_search("localhost:\d+|UseUrls.*\d+", isRegexp=true)` before assuming service responsibilities
-   **Never assume service ownership:** Always verify implementation patterns with actual code evidence
-   **Platform-first approach:** Use established templates from `ai-context-prompt.md` instead of custom solutions
-   **Cross-service sync:** Use Entity Event Bus patterns, never direct database access between services
-   **Repository patterns:** Use platform repository + extensions instead of custom interfaces
-   **Investigation workflow:** 1) Extract domain concepts → 2) semantic_search() → 3) grep_search() → 4) Service discovery → 5) Evidence assessment → 6) Platform patterns

---

---

## 1. Code Review and Refactoring

**PREREQUISITE:** #codebase Apply the Universal Improvement Guidelines in `ai-common-prompt.md` throughout all phases of this workflow.

You are to operate as an expert principal AI developer to analyze and refactor the file `[file-name]` according to the task in `[task-description-or-task-info-file-path]`. **PHASE 1: KNOWLEDGE MODEL CONSTRUCTION.** Your sole objective is to build a structured knowledge model in a file named `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml`, NOT to write or plan code yet. First, initialize the notes file by add my full original prompt into it at the top, then add summarizing the project architecture and structure in `ai-context-prompt.md`, task description, and this prompt under a `metadata:` key. Add `progress: { phase: 1, itemsProcessed: 0, totalItems: 0, currentOperation: "initialization" }` and `errors: []` keys. Next, perform a graph traversal analysis with **SCOPE BOUNDARIES**: initialize a `workQueue` with `[file-name]` and a `processedItems` set, limiting to maximum 20 items. While the `workQueue` is not empty, dequeue an `itemPath`, and if not already processed, add it to the `processedItems` set and populate a new entry in to the notes file under the `knowledgeGraph:` key using the `itemPath` as the unique ID. For each item, you MUST populate a YAML object with these keys: `type`, `filePath`, `usages` (by finding all references first to determine relevance), `definition` (for files >500 lines, store `structureSummary` instead of full source code), `dependencies` (adding any new, unprocessed paths to the `workQueue` within scope limits), `inheritanceChain` (recursively tracing to maximum 3 levels deep), `architecturalPattern` (e.g., CQRS Handler, Presentation Component), `relevanceScore` (1-3), and `members` (listing own, inherited, and protected methods/properties). **KNOWLEDGE VALIDATION:** After processing, validate your knowledge model by spot-checking 3 random entries: verify file paths exist, verify inheritance chains are accurate, verify architectural patterns match actual code. Document validation results under `validationResults:` key. This structured YAML is your mandatory, persistent memory. **PHASE 2: PLAN GENERATION.** Auto run phase 2, no need to ask for confirmation. Your entire world is the `ai_task_analysis_notes_temp file` you created. Read the ENTIRE the `ai_task_analysis_notes_temp file` one final time first before doing anything else. Then, based exclusively on this knowledge model, generate a detailed, step-by-step refactoring plan under a `plan:` key. For each step, you MUST cite the specific entries in your `knowledgeGraph` that justify the change and ensure the plan follows the 'Clean Code Rules' from ai-context-prompt.md and aligns with the discovered `architecturalPattern`. **PHASE PREREQUISITES:** Verify minimum 5 knowledgeGraph entries, validated file paths, identified architectural patterns before proceeding. **AUTO-PROCEED TO PHASE 2:** Automatically proceed to Phase 2 after completing Phase 1 without asking for approval. **PHASE 3: APPROVAL GATE.** You must present the generated plan for my explicit approval. DO NOT proceed without it. **PHASE 4: EXECUTION.** Once approved, execute the plan. Load the `ai-context-prompt.md` for AI Agent context and read ENTIRE the notes file one final time first before doing anything else. For EACH file you modify, you MUST first load its specific entry from the `knowledgeGraph` in `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml` to refresh your immediate context. **SUCCESS VALIDATION:** Before marking complete, verify implementation against original requirements: all features implemented, no regressions introduced, coding standards followed. Document verification under `successValidation:` key. Upon successful completion, maintain EXACT original file formatting, validate no new errors were introduced, and summarize your changes in `changelog.md`.

---

---

## 2. Documentation Enhancement

**PREREQUISITE:** #codebase Apply the Universal Improvement Guidelines in `ai-common-prompt.md` throughout all phases of this workflow.

You are to operate as an expert AI technical writer to generate documentation for `[files/features/directory]` per `[task-description-or-task-info-file-path]`, without modifying code logic. **PHASE 1: KNOWLEDGE MODEL CONSTRUCTION.** Your sole objective is to build a structured knowledge model in a file named `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml`, NOT to write or plan code yet. First, initialize the notes file by add my full original prompt into it at the top, then add summarizing the project architecture and structure in `ai-context-prompt.md`, task description, documentation standards, and this prompt under a `metadata:` key. Add `progress: { phase: 1, itemsProcessed: 0, totalItems: 0, currentOperation: "initialization" }` and `errors: []` keys. **DOCUMENTATION STANDARDS:** Check for existing documentation patterns in the codebase (README.md, API docs, inline comments). Adopt the same format, tone, and structure. Document the discovered standards under `documentationStandards:` key. Next, perform a graph traversal analysis with **SCOPE BOUNDARIES**: initialize a `workQueue` with the starting files in `[files/features/directory]` and a `processedItems` set, limiting to maximum 20 items. While the `workQueue` is not empty, dequeue an `itemPath`, and if not already processed, add it to `processedItems` and populate a new entry in to the notes file under the `knowledgeGraph:` key using the `itemPath` as the unique ID. For each item, you MUST populate a YAML object with these keys: `type`, `filePath`, `usages` (to understand its role), `definition` (for files >500 lines, store `structureSummary` instead of full source code), `dependencies` (adding new paths to the `workQueue` within scope limits), `inheritanceChain` (recursively tracing to maximum 3 levels deep), `architecturalPattern`, `relevanceScore` (1-3), and `members` (own and inherited). **KNOWLEDGE VALIDATION:** After processing, validate your knowledge model by spot-checking 3 random entries: verify file paths exist, verify inheritance chains are accurate, verify architectural patterns match actual code. Document validation results under `validationResults:` key. This structured YAML is your mandatory, persistent memory. **PHASE 2: PLAN GENERATION.** Auto run phase 2, no need to ask for confirmation. Load the `ai-context-prompt.md` for AI Agent context and read ENTIRE the notes file one final time first before doing anything else. Based exclusively on this knowledge model, generate a detailed documentation plan under a `plan:` key. For each item to be documented, explain what you will write and why, citing evidence from its `knowledgeGraph` entry (e.g., "Document the `title` prop's purpose by referencing its usage in `HomePage.tsx`"). **PHASE PREREQUISITES:** Verify minimum 5 knowledgeGraph entries, documented standards, identified architectural patterns before proceeding. **AUTO-PROCEED TO PHASE 2:** Automatically proceed to Phase 2 after completing Phase 1 without asking for approval. **PHASE 3: APPROVAL GATE.** You must present the generated plan for my explicit approval. DO NOT proceed without it. **PHASE 4: EXECUTION.** Once approved, execute the plan. Load the `ai-context-prompt.md` for AI Agent context and read ENTIRE the notes file one final time first before doing anything else. For EACH file you are documenting, you MUST first load its specific entry from the `knowledgeGraph` in `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml` to refresh your immediate context. **SUCCESS VALIDATION:** Before marking complete, verify documentation completeness, accuracy, and adherence to discovered standards. Document verification under `successValidation:` key. Upon successful completion, summarize your documentation enhancements in `changelog.md`.

---

---

## 3. Implementing a New Feature or Enhancement

**PREREQUISITE:** #codebase Apply the Universal Improvement Guidelines in `ai-common-prompt.md` throughout all phases of this workflow.

You are to operate as an expert full-stack dotnet angular senior developer to implement the new requirements in `[task-description-or-task-info-file-path]`. **PHASE 1: KNOWLEDGE MODEL CONSTRUCTION.** Your sole objective is to build a structured knowledge model in a file named `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml`, NOT to write or plan code yet. First, initialize the notes file by add my full original prompt into it at the top, then add summarizing the project architecture and structure in `ai-context-prompt.md`, task description, and this prompt under a `metadata:` key. Add `progress: { phase: 1, itemsProcessed: 0, totalItems: 0, currentOperation: "initialization" }` and `errors: []` keys. **PATTERN IDENTIFICATION:** Before starting graph traversal, use semantic_search to find 3 most similar existing features by searching for keywords from the requirement. Document pattern confidence scores (High/Medium/Low) and prefer High-confidence patterns for replication under `patternAnalysis:` key. Next, perform a graph traversal analysis with **SCOPE BOUNDARIES**: start by identifying similar existing features to find established patterns, then initialize a `workQueue` with the file paths of those similar features and a `processedItems` set, limiting to maximum 20 items. Prioritize items by relevance score (direct dependencies = 3, inheritance = 2, usage = 1). While the `workQueue` is not empty, dequeue an `itemPath`, and if not already processed, add it to `processedItems` and populate a new entry in to the notes file under the `knowledgeGraph:` key using the `itemPath` as the unique ID. For each item, you MUST first populate a YAML object with these keys: `type`, `filePath`, `usages`, `definition` (for files >500 lines, store `structureSummary` instead of full source code), `dependencies` (adding new paths to the `workQueue` within scope limits), `inheritanceChain` (recursively tracing to maximum 3 levels deep), `architecturalPattern` (CRITICAL to replicate this), `relevanceScore` (1-3), and `members` (own and inherited). Immediately after, you MUST perform a **Targeted Aspect Analysis** by populating a `specificAspects` key in its YAML entry. **For Front-End items, you MUST log:** the full `componentHierarchy` of a page, its `routeConfig` and any `routeGuards`, and its connections to `stateManagementStores` (view-model/ui-state/data-state) and injected `services`. **For Back-End items, you MUST log:** `authorizationPolicies` for controllers, related `commands`, `queries`, `domainEntities`, `DTOs`, `eventHandlers`, `backgroundJobs` (including recurring), `messageQueue` interactions (consumer/producer), and any usage of the `requestContext` (identifying keys and extension methods for user/security data). **KNOWLEDGE VALIDATION:** After processing, validate your knowledge model by spot-checking 3 random entries: verify file paths exist, verify inheritance chains are accurate, verify architectural patterns match actual code. Document validation results under `validationResults:` key. This structured YAML is your mandatory, persistent memory. **PHASE 2: PLAN GENERATION.** Auto run phase 2, no need to ask for confirmation. Load the `ai-context-prompt.md` for AI Agent context and read ENTIRE the notes file one final time first before doing anything else. Based exclusively on this knowledge model, generate a detailed, step-by-step implementation plan under a `plan:` key into `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml` file. Your plan MUST explicitly state how it will replicate the `architecturalPattern` and `specificAspects` discovered from existing features and follow the 'Clean Code Rules' from ai-context-prompt.md. For any front-end changes, the plan MUST prioritize reusing existing data states as identified in the `knowledgeGraph` before proposing new API calls. **PHASE PREREQUISITES:** Verify minimum 5 knowledgeGraph entries, validated file paths, identified architectural patterns, pattern confidence scores before proceeding. **AUTO-PROCEED TO PHASE 2:** Automatically proceed to Phase 2 after completing Phase 1 without asking for approval. **PHASE 3: APPROVAL GATE.** You must present the generated plan for my explicit approval. DO NOT proceed without it. **PHASE 4: EXECUTION.** Once approved, execute the plan. Load the `ai-context-prompt.md` for AI Agent context and read ENTIRE the notes file one final time first before doing anything else. Create a consolidated `executionContext:` summary containing only essential information for implementation. Every time before creating or modifying ANY file, you MUST first load the most relevant entries from your `knowledgeGraph` in `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml` and load most relevant example code in `ai-context-prompt.md` to refresh your immediate context. **SUCCESS VALIDATION:** Before marking complete, verify implementation against original requirements: all features implemented, patterns replicated correctly, no regressions introduced, coding standards followed. Document verification under `successValidation:` key. Upon successful completion, conduct a final self-review and summarize your changes in `changelog.md`.

---

---

## 4. Improve README.md File

**PREREQUISITE:** #codebase Apply the Universal Improvement Guidelines in `ai-common-prompt.md` throughout all phases of this workflow.

You are to operate as an expert AI technical writer and architect to create a new, comprehensive `README_v2.md` file per `[task-description-or-task-info-file-path]`. **PHASE 1: KNOWLEDGE MODEL CONSTRUCTION.** Your sole objective is to build a structured knowledge model in a file named `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml`, NOT to write or plan code yet. First, initialize the notes file by add my full original prompt into it at the top, then add summarizing the current `README.md`, task description, and this prompt under a `metadata:` key. Add `progress: { phase: 1, itemsProcessed: 0, totalItems: 0, currentOperation: "initialization" }` and `errors: []` keys. Next, perform a targeted graph traversal analysis with **SCOPE BOUNDARIES**: initialize a `workQueue` with entry points of the application (e.g., `main.ts`, `App.tsx`) and a `processedItems` set, limiting to maximum 20 items. Your goal is not to map every file, but to identify and map the core components that define the architecture. Prioritize items by relevance score (core architecture = 3, supporting = 2, peripheral = 1). While the `workQueue` is not empty, dequeue an `itemPath`, and if not already processed, add it to `processedItems` and populate a new entry in to the notes file under `knowledgeGraph:`. For each major architectural component, you MUST populate a YAML object focused on: `type`, `filePath`, `architecturalPattern` (e.g., "CQRS Command Handler Base Class," "Global State Provider"), a brief `description` of its role, `relevanceScore` (1-3), and its `dependencies` on other major components (adding them to the `workQueue` within scope limits). **KNOWLEDGE VALIDATION:** After processing, validate your knowledge model by spot-checking 3 random entries: verify file paths exist, verify architectural patterns are accurately described, verify dependencies are correct. Document validation results under `validationResults:` key. This structured YAML is your mandatory, persistent memory. **PHASE 2: OUTLINE GENERATION.** After populating `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml`, you are forbidden from reading the codebase directly. Read the ENTIRE the `ai_task_analysis_notes_temp file` one final time first before doing anything else. Based exclusively on the distilled patterns in your knowledge model, generate a detailed outline or structured plan for the new `README_v2.md` under a `plan:` key. The outline must focus on clearly explaining the core architectural patterns you discovered, how they connect, and providing validated code examples. **PHASE PREREQUISITES:** Verify minimum 5 knowledgeGraph entries for core architectural components, validated patterns, clear dependencies before proceeding. **AUTO-PROCEED TO PHASE 2:** Automatically proceed to Phase 2 after completing Phase 1 without asking for approval. **PHASE 3: APPROVAL GATE.** You must present the generated plan for my explicit approval. DO NOT proceed without it. **PHASE 4: EXECUTION.** Once approved, execute the plan to write the full `README_v2.md` file. You MUST use only your `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml` and the approved outline as your source of truth. Create a consolidated `executionContext:` summary containing only essential information for writing. **SUCCESS VALIDATION:** Before marking complete, verify README completeness, accuracy of architectural descriptions, and usefulness for developers. Document verification under `successValidation:` key. Your task is complete upon successful generation of the `README_v2.md` file.

## 5. Full-Stack Feature Analysis and Test Case Generation

**PREREQUISITE:** #codebase Apply the Universal Improvement Guidelines in `ai-common-prompt.md` throughout all phases of this workflow.

You are to operate as an expert AI full-stack QA engineer and Software Developer in Test (SDET) to analyze the feature described in `[feature_description_or_file_paths]` and generate a comprehensive set of test cases. **PHASE 1: KNOWLEDGE MODEL CONSTRUCTION.** Your sole objective is to build a structured knowledge model in a file named `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml`, NOT to write or plan code yet. First, initialize the notes file by add my full original prompt into it at the top, then add summarizing the project architecture and structure in `ai-context-prompt.md`, feature description, and this prompt under a `metadata:` key. Add `progress: { phase: 1, itemsProcessed: 0, totalItems: 0, currentOperation: "initialization" }` and `errors: []` keys. Next, perform a graph traversal analysis with **SCOPE BOUNDARIES**: initialize a `workQueue` with the starting file paths or keywords from the feature description and a `processedItems` set, limiting to maximum 20 items. Prioritize items by relevance score (feature-specific = 3, dependencies = 2, infrastructure = 1). While the `workQueue` is not empty, dequeue an `itemPath`, and if not already processed, add it to `processedItems` and populate a new entry in to the notes file under the `knowledgeGraph:` key using the `itemPath` as the unique ID. For each item, you MUST first populate a YAML object with these keys: `type`, `filePath`, `usages`, `definition` (for files >500 lines, store `structureSummary` instead of full source code), `dependencies` (adding new paths to the `workQueue` within scope limits), `inheritanceChain` (recursively tracing to maximum 3 levels deep), `architecturalPattern`, `relevanceScore` (1-3), and `members` (own and inherited). Immediately after, you MUST perform a **Targeted Aspect Analysis** by populating a `specificAspects` key in its YAML entry. **For Front-End items, you MUST log:** the full `componentHierarchy`, its `routeConfig` and `routeGuards`, its connections to `stateManagementStores`, and its data validation logic. **For Back-End items, you MUST log:** `authorizationPolicies`, `commands`, `queries`, `domainEntities` (including validation rules), `eventHandlers`, `backgroundJobs`, and `messageQueue` interactions. **KNOWLEDGE VALIDATION:** After processing, validate your knowledge model by spot-checking 3 random entries: verify file paths exist, verify validation rules are captured, verify authorization flows are documented. Document validation results under `validationResults:` key. This structured YAML is your mandatory, persistent memory. **PHASE 2: TEST CASE GENERATION.** Your entire world is the `ai_task_analysis_notes_temp file` you created. Read the ENTIRE the `ai_task_analysis_notes_temp file` one final time first before doing anything else. Based exclusively on this knowledge model, generate a comprehensive suite of test cases under a `testCases:` key in a new YAML plan file. The test cases must cover happy paths, edge cases, and failure scenarios (e.g., authorization failures, validation errors, API errors). Each test case MUST follow the "Given-When-Then" format and cite the specific entries from your `knowledgeGraph` that justify its existence. **COVERAGE ANALYSIS:** After generating test cases, analyze coverage gaps by checking for untested: validation rules, error conditions, authorization paths, and edge cases. Document coverage percentage and gaps under `coverageAnalysis:` key. **PHASE PREREQUISITES:** Verify minimum 5 knowledgeGraph entries, captured validation rules, identified authorization flows, architectural patterns before proceeding. **AUTO-PROCEED TO PHASE 2:** Automatically proceed to Phase 2 after completing Phase 1 without asking for approval. **PHASE 3: APPROVAL GATE.** You must present the generated plan for my explicit approval. DO NOT proceed without it. **PHASE 4: EXECUTION.** Once approved, you will write overall detailed requirements of feature and the generated test cases into a new markdown file based on `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml`. The file MUST be created in the `test-cases/` directory and named `[name_of_the_feature].test-case.md`. You must format the output cleanly using markdown, with each test case clearly separated. Create a consolidated `executionContext:` summary containing only essential information for writing. **SUCCESS VALIDATION:** Before marking complete, verify test case completeness, coverage adequacy, and adherence to Given-When-Then format. Document verification under `successValidation:` key. After creating the file, your task is complete.

## 6. Generate copilot-instructions.md

**PREREQUISITE:** #codebase Apply the Universal Improvement Guidelines in `ai-common-prompt.md` throughout all phases of this workflow.

You are to operate as an expert full-stack dotnet angular senior developer to implement the new requirements in `Generate a copilot-instructions.md file describe the project structure and architecture. Describe all platform or base component in the project. Describe all code example for back-end code standard in growth project, front-end example code standard in WebV2 project, all aspect like how to create a new api service to controller in backend, where to place domain component, common component, platform data domain model, feature component store component, form component, example how to handle loading data and load data or call api by using simple effect, how to use store, use vm component, how to handle load data on init component correctly, how to handle reload data for component, how to do all aspect in backend like command, query, event handler, consumer, producer, event producer, background job, recurring background job, check custom domain event in entity event, check property updated domain event in entity event, how to use request context in query, command, consumer, event handler. How to handle authorize in backend by policy. how handler authorize in front-end by guard and auth service. how handle prevent navigation guard and display/hidden navigation in both webv2 and web old v1. All given with example snippet code. The goal is to help AI agent know all coding convention in the project to work properly.`. **PHASE 1: KNOWLEDGE MODEL CONSTRUCTION.** Your sole objective is to build a structured knowledge model in `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml`. First, initialize `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml` by add my full original prompt into it at the top, then add summarizing the project `README.md`, task description, and this prompt under a `metadata:` key. Add `progress: { phase: 1, itemsProcessed: 0, totalItems: 0, currentOperation: "initialization" }` and `errors: []` keys. **PATTERN IDENTIFICATION:** Before starting graph traversal, use semantic_search to find 3 most similar existing features by searching for keywords related to coding standards, architectural patterns, and example implementations. Document pattern confidence scores (High/Medium/Low) and prefer High-confidence patterns for documentation under `codingStandardsAnalysis:` key. Next, perform a graph traversal analysis with **SCOPE BOUNDARIES**: start by identifying similar existing features to find established patterns, then initialize a `workQueue` with the file paths of those similar features and a `processedItems` set, limiting to maximum 20 items. Prioritize items by relevance score (core patterns = 3, examples = 2, supporting = 1). While the `workQueue` is not empty, dequeue an `itemPath`, and if not already processed, add it to `processedItems` and populate a new entry in to the notes file under the `knowledgeGraph:` key using the `itemPath` as the unique ID. For each item, you MUST first populate a YAML object with these keys: `type`, `filePath`, `usages`, `definition` (for files >500 lines, store `structureSummary` instead of full source code), `dependencies` (adding new paths to the `workQueue` within scope limits), `inheritanceChain` (recursively tracing to maximum 3 levels deep), `architecturalPattern` (CRITICAL to replicate this), `relevanceScore` (1-3), and `members` (own and inherited). Immediately after, you MUST perform a **Targeted Aspect Analysis** by populating a `specificAspects` key in its YAML entry. **For Front-End items, you MUST log:** the full `componentHierarchy` of a page, its `routeConfig` and any `routeGuards`, and its connections to `stateManagementStores` (view-model/ui-state/data-state) and injected `services`. **For Back-End items, you MUST log:** `authorizationPolicies` for controllers, related `commands`, `queries`, `domainEntities`, `DTOs`, `eventHandlers`, `backgroundJobs` (including recurring), `messageQueue` interactions (consumer/producer), and any usage of the `requestContext` (identifying keys and extension methods for user/security data). **KNOWLEDGE VALIDATION:** After processing, validate your knowledge model by spot-checking 3 random entries: verify file paths exist, verify coding patterns are accurately captured, verify architectural examples are complete. Document validation results under `validationResults:` key. This structured YAML is your mandatory, persistent memory. **PHASE 2: PLAN GENERATION.** Auto run phase 2, no need to ask for confirmation. Load the `ai-context-prompt.md` for AI Agent context and read ENTIRE the notes file one final time first before doing anything else. Based exclusively on this knowledge model, generate a detailed, step-by-step implementation plan under a `plan:` key into `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml` file. Your plan MUST explicitly state how it will replicate the `architecturalPattern` and `specificAspects` discovered from existing features and follow the 'Clean Code Rules' from README.md. For any front-end changes, the plan MUST prioritize reusing existing data states as identified in the `knowledgeGraph` before proposing new API calls. **PHASE PREREQUISITES:** Verify minimum 5 knowledgeGraph entries, captured coding standards, identified architectural patterns, pattern confidence scores before proceeding. **AUTO-PROCEED TO PHASE 2:** Automatically proceed to Phase 2 after completing Phase 1 without asking for approval. **PHASE 3: APPROVAL GATE.** You must present the generated plan for my explicit approval. DO NOT proceed without it. **PHASE 4: EXECUTION.** Once approved, execute the plan. Load the `ai-context-prompt.md` for AI Agent context and read ENTIRE the notes file one final time first before doing anything else. Create a consolidated `executionContext:` summary containing only essential information for implementation. Every time before creating or modifying ANY file, you MUST first load the most relevant entries from your `knowledgeGraph` in `ai_task_analysis_notes_temp/[some-sort-semantic-name-of-this-task].ai_task_analysis_notes_temp.yaml` and load most relevant example code in `ai-context-prompt.md` to refresh your immediate context. **SUCCESS VALIDATION:** Before marking complete, verify copilot-instructions.md completeness, accuracy of patterns, usefulness of examples, and coverage of all requested areas. Document verification under `successValidation:` key. Upon successful completion, conduct a final self-review and summarize your changes in `changelog.md`.
